{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatchLab-Imperial/deep-learning-course/blob/master/10_Data_Classification_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üè† Data collection and classification Challenge ‚Äî YOLOv8\n",
        "\n",
        "**Objective:** You have been hired as an AI expert and your new boss, who knows nothing about AI, asked you to quickly develop a DL model that can classify roofs in the UK from aerial views. The input is in the form of image crops from Google satellite views, each containing one building. Some crops may contain a few buildings but it can be considered as noise. You should collect data and finetune `yolov8n-cls.pt`  model.   Classify aerial roof images into **flat** or **pitched**. These are the constraints, otherwise you are free to make your own design choices.\n",
        "\n",
        "- Tune training hyperparameters  \n",
        "- Add more images to improve your model  \n",
        "- Experiment with augmentation or optimization settings  \n",
        "\n",
        "When you are satisfied, submit the annotated data `*CID*_data.zip` with the same file structure as the provided sample as well as your best `*CID*_best.pt` checkpoint, which will be evaluated on a hidden test set. Keep the filenames of the existing samples as they are.\n",
        "\n",
        "---\n",
        "\n",
        "### üìÅ Expected dataset structure\n",
        "<pre>\n",
        ".../aerial\n",
        "‚îú‚îÄ train/\n",
        "‚îÇ ‚îú‚îÄ flat/\n",
        "‚îÇ ‚îî‚îÄ pitched/\n",
        "‚îú‚îÄ val/\n",
        "‚îÇ ‚îú‚îÄ flat/\n",
        "‚îÇ ‚îî‚îÄ pitched/\n",
        "‚îî‚îÄ test/\n",
        "  ‚îú‚îÄ flat/\n",
        "  ‚îî‚îÄ pitched/\n",
        "</pre>\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Notes\n",
        "\n",
        "- You will train only the classification model `yolov8n-cls.pt`.\n",
        "\n",
        "- Image size (`imgsz`):  \n",
        "  - YOLOv8 automatically resizes any input to the `imgsz` you set in `model.train(...)`.  \n",
        "  - Tip: using sizes that are multiples of 32 (224, 256, 320, 384, ‚Ä¶) aligns well with the backbone. Larger sizes train slower, but can perform better.\n",
        "  - When collecting images, there‚Äôs no strict size rule; just aim for **clear roofs**.\n",
        "\n",
        "- Collecting more images:\n",
        "  - Sources: **Google Earth**, **OpenAerialMap**, **Mapillary**, **Kaggle**, public GIS/satellite portals, or your **own drone/photos**.  \n",
        "  - Prefer images that aren‚Äôt tiny/blurry/over-compressed. RGB `.jpg/.jpeg/.png/.bmp/.webp` are all fine.\n",
        "\n",
        "- Adding new data to `/aerial`:\n",
        "  1. Label by roof type and drop files into the correct folders locally:\n",
        "     ```\n",
        "     aerial/\n",
        "     ‚îú‚îÄ train/\n",
        "     ‚îÇ  ‚îú‚îÄ flat/\n",
        "     ‚îÇ  ‚îî‚îÄ pitched/\n",
        "     ‚îú‚îÄ val/\n",
        "     ‚îÇ  ‚îú‚îÄ flat/\n",
        "     ‚îÇ  ‚îî‚îÄ pitched/\n",
        "     ‚îî‚îÄ test/\n",
        "        ‚îú‚îÄ flat/\n",
        "        ‚îî‚îÄ pitched/\n",
        "     ```\n",
        "  2. Do **not** duplicate the same image across `train/`, `val/`, and `test/`.\n",
        "  3. Compress local folder to [aerial.zip](https://github.com/MatchLab-Imperial/deep-learning-course/blob/master/asset/10_Classification_YOLO/aerial.zip) to upload to colab in the code block below.\n",
        "\n"
      ],
      "metadata": {
        "id": "Cwhwuz-RJvpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q ultralytics  # uncomment if not installed\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random, torch\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # choose aerial.zip"
      ],
      "metadata": {
        "id": "nLQI6pm8KChg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o aerial.zip -d /content/\n",
        "!find /content/aerial -maxdepth 2 -type d -print  # quick check"
      ],
      "metadata": {
        "id": "xiRXQ8T4KOQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = Path(\"/content/aerial\")\n",
        "assert (DATA_ROOT/\"train\").exists() and (DATA_ROOT/\"val\").exists(), \"train/val folders missing\"\n",
        "\n",
        "# List classes from train/\n",
        "classes = sorted([p.name for p in (DATA_ROOT/\"train\").iterdir() if p.is_dir()])\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "# Collect sample images\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
        "samples = []\n",
        "for cls in classes:\n",
        "    samples += [p for p in (DATA_ROOT/\"train\"/cls).iterdir() if p.suffix.lower() in exts]\n",
        "\n",
        "random.shuffle(samples)\n",
        "show = samples[:6]\n",
        "\n",
        "# Plot\n",
        "cols = 3\n",
        "rows = 2\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, p in enumerate(show, 1):\n",
        "    img = Image.open(p)\n",
        "    plt.subplot(rows, cols, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(p.parent.name)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5TzcSDQkJ8X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ† Training Tips ‚Äî Things You Can Try\n",
        "\n",
        "You may experiment with these arguments in `model.train()`:\n",
        "\n",
        "| Parameter | Meaning | Suggested values |\n",
        "|-----------|---------|------------------|\n",
        "| `imgsz` | input image size | `224`, `320`, `384` |\n",
        "| `epochs` | training duration | `10‚Äì60` |\n",
        "| `batch` | batch size | `16‚Äì128` |\n",
        "| `auto_augment` | built-in augmentation | `\"randaugment\"`, `\"ta_wide\"` |\n",
        "| `mixup` / `cutmix` | label mixing | `0.0‚Äì0.3` |\n",
        "| `erasing` | random erasing | `0.0‚Äì0.7` |\n",
        "| `optimizer` | optimizer choice | `\"SGD\"` or `\"AdamW\"` |\n",
        "| `cos_lr` | cosine LR schedule | `True` or `False` |\n",
        "\n",
        "Tip: only change one or two things at a time, and always monitor `top1_acc`. (`top5_acc` is printed automatically in YOLO classification tasks, but is useless in our two-class task.)\n"
      ],
      "metadata": {
        "id": "mJBv8dqeKTYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = Path(\"/content/aerial\")\n",
        "assert (DATA_ROOT/\"train\").exists(), \"train folder missing\"\n",
        "assert (DATA_ROOT/\"val\").exists(), \"val folder missing\"\n",
        "assert (DATA_ROOT/\"test\").exists(), \"test folder missing\"\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Loading base model\n",
        "model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "# ======== TRAIN (you may edit arguments below) ========\n",
        "results = model.train(\n",
        "    data=str(DATA_ROOT),     # uses train/ and val/\n",
        "    imgsz=320,               # try 224/320/384\n",
        "    epochs=30,               # increase if val improves\n",
        "    batch=64,\n",
        "    device=device,\n",
        "    workers=2,\n",
        "    patience=10,\n",
        "    auto_augment=\"randaugment\",\n",
        "    erasing=0.5,\n",
        "    mixup=0.1,\n",
        "    cutmix=0.1,\n",
        "    # optimizer=\"AdamW\",\n",
        "    # cos_lr=True,\n",
        "    verbose=False,           # <-- minimising console output\n",
        "    plots=False,             # <-- skipping plots\n",
        ")\n",
        "\n",
        "best_ckpt = model.trainer.best\n",
        "print(\"Best checkpoint to submit:\", best_ckpt)\n",
        "\n",
        "# ======== TEST (held-out split) ========\n",
        "metrics = model.val(\n",
        "    data=str(DATA_ROOT),\n",
        "    split=\"test\",\n",
        "    imgsz=320,\n",
        "    device=device,\n",
        "    verbose=False,           # <-- minimising console output\n",
        ")\n",
        "print(f\"Test: {100*metrics.top1:.4f}%\")\n"
      ],
      "metadata": {
        "id": "lDsBAHBaKX2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíæ Saving and Submitting Your Model\n",
        "\n",
        "**Report**:\n",
        "\n",
        "*   Report the classification performance you achieved.\n",
        "*   Present details of your training data and training parameters such that someone can reproduce your experiment.\n",
        "*   Include a figure with the learning curves. \n\n",
        "Once training is complete, you‚Äôll download your best-performing model checkpoint for submission.  \n",
         "\n",
        "Follow the short prompt below to enter your **CID** ‚Äî this will automatically rename your `best.pt` file (to `*CID*_best.pt`) and trigger the download. \n\n"


      ],
      "metadata": {
        "id": "i_ofpyxyprkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, shutil\n",
        "\n",
        "# Ensuring best_ckpt exists\n",
        "assert 'best_ckpt' in globals(), \"Run the training cell first to define `best_ckpt`.\"\n",
        "src = Path(best_ckpt)\n",
        "assert src.exists(), f\"Checkpoint not found at: {src}\"\n",
        "\n",
        "\n",
        "cid = input(\"Enter your College ID: \").strip()\n",
        "cid = re.sub(r'[^0-9]', '', cid)\n",
        "if not cid:\n",
        "    raise ValueError(\"Invalid College ID. Please use digits only (0‚Äì9).\")\n",
        "\n",
        "\n",
        "dst = Path(f\"/content/{cid}_best.pt\")\n",
        "shutil.copy(src, dst)\n",
        "print(f\"Prepared submission file: {dst}\")\n",
        "\n",
        "# Downloading\n",
        "files.download(str(dst))"
      ],
      "metadata": {
        "id": "RUrwLYKfMgKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
